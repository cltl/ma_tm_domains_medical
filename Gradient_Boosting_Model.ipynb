{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:20,.5f}'.format\n",
    "sns.set()\n",
    "\n",
    "SEED = random.seed(0)\n",
    "DATA = Path('data')\n",
    "MODELS = Path('models')\n",
    "EXPERIMENTS = Path('experiments')\n",
    "TARGETS = ['participants','interventions','outcomes']\n",
    "SUBSET = 'Train' # 'Test'\n",
    "N_TRAIN_DOCS = 4500\n",
    "BASE_MODEL_NAME = 'GBC_POS-PMFT' # GradBoostClassifier model trained on dataset 'raw', with POS tag and \n",
    "                                    # PubMed data-trained FastText as features.    \n",
    "# DOWNSAMPLE = False \n",
    "\n",
    "# add required libraries etc\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.read_parquet('data/split/train.parquet') # attach words to the training set\n",
    "\n",
    "# the test set is currently withheld. Test using a validation split (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotcoding categorical columns...\n",
      "set()\n",
      "No categorical values found in data\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"8caba081-3587-4506-bc49-6d68634f1b57\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"8caba081-3587-4506-bc49-6d68634f1b57\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "\n",
    "def hotcode(df):\n",
    "    \n",
    "\n",
    "    num_cols = df._get_numeric_data().columns\n",
    "    cat_cols = (set(df.columns) - set(num_cols)) - {'Word'}\n",
    "    \n",
    "    print(cat_cols)\n",
    "    dummies = pd.get_dummies(df[cat_cols])\n",
    "    \n",
    "    print('hotcode complete.')\n",
    "    # assert check that type is numeric for all\n",
    "    \n",
    "    return pd.concat([dummies, df[num_cols]], axis=1)\n",
    "\n",
    "# print('Word' in features)\n",
    "# print(train_val.shape)\n",
    "\n",
    "print('hotcoding categorical columns...')\n",
    "try:\n",
    "    train_val = hotcode(train_val)\n",
    "except ValueError:\n",
    "    print('No categorical values found in data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Parameters & Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and validation split is only an example for K-fold crossvalidation to simulate an 80:20 train/validation dataset. See code examples of  https://scikit-learn.org/stable/modules/cross_validation.html and https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name set to GradBoost_0309-1800\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_NAME = 'GradBoost'\n",
    "k_folds = 5 # not implemented\n",
    "time = datetime.now().strftime(\"%m%d-%H%M\")\n",
    "\n",
    "pio = {\"participants\", \"interventions\", \"outcomes\"}\n",
    "features = set(train_val.columns).difference(pio.union({'Word'}))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f_score', 'support']\n",
    "\n",
    "dir_name = BASE_MODEL_NAME  + f'_{time}'\n",
    "print(f'Folder name set to {dir_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Validation split (KCV currently not implemented, so just a simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting data 3600:900\n"
     ]
    }
   ],
   "source": [
    "train_idx, val_idx = train_test_split(train_val.index.unique('doc'), \n",
    "                                      train_size=1-(1/k_folds)) # default 70:30\n",
    "\n",
    "print(f'splitting data {len(train_idx)}:{len(val_idx)}')\n",
    "\n",
    "train_set = train_val.loc[(train_idx, slice(None)),:]\n",
    "val_set   = train_val.loc[(val_idx, slice(None)),:]\n",
    "\n",
    "X_train, X_test = train_set[features], val_set[features]\n",
    "y_train, y_test = train_set[pio.union({'Word'})], val_set[pio.union({'Word'})]\n",
    "\n",
    "# copies = [deepcopy(data) for data in [X_train, y_train, X_test, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# convert labels to string (pd.Categorical?)\n",
    "y_train, y_test = [pd.concat([y[key].astype('str') for key in y],axis=1) for y in [y_train, y_test]]\n",
    "\n",
    "print(f\"Evluating model on validation set(s) of size {len(val_set)} with {len(val_set.index.unique('doc'))} documents\")\n",
    "print(f'Prepared dataset has {len(features)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Train a model for each feature. Can also try a multiclass model, since only 3% of the labels overlap.\n",
    "\n",
    "The model trains n_estimators, which are binary decision trees on a single feature. 'Boosting' refers to the fact that the trees learn to choose the most informative variables over generations, meaning the score gradually improves. The aggregate label prediction for each word is taken over all estimators. There are many tunable parameters for this model but for initial testing I've used 300 estimators and 416 features (meaning not all features will be explored, see the feature importance results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = TARGETS # choose which variables you want to predict\n",
    "n_estimators = 3\n",
    "n_runs = 1\n",
    "weight_factor = 2 # weight factor of positive class compared to negative\n",
    "\n",
    "words = pd.read_pickle('data\\\\raw\\\\labels.pkl')\n",
    "\n",
    "assert \"Word\" not in features\n",
    "assert np.array([(label not in features) for label in pio]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "\n",
    "# dump params to file\n",
    "\n",
    "for run in range(n_runs):\n",
    "    \n",
    "    # cross-validation parameters should be configured here\n",
    "\n",
    "    train_weights = y_train[pio].astype(int) * (1 - 1/weight_factor) + 1 / weight_factor\n",
    "    test_weights = y_test[pio].astype(int) * (1 - 1/weight_factor) + 1 / weight_factor\n",
    "        \n",
    "    for target in TARGETS:\n",
    "        \n",
    "        print(f\"Training GradientBoosting model to predict {target} \"\n",
    "              f\"on {len(X_train.index.unique('doc'))} training instances \" \n",
    "              f\"for label {target}\")\n",
    "\n",
    "        clf = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=1.0, \n",
    "                                         verbose=1, max_depth=1, random_state=0)\n",
    "              \n",
    "        clf = clf.fit(X_train, y_train[target], sample_weight=train_weights[target].values)\n",
    "              \n",
    "        score = clf.score(X_test, y_test[target], sample_weight=test_weights[target].values)\n",
    "              \n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_true = y_test[target].values \n",
    "              \n",
    "        print(f'Saving data for run {run}, target {target} in {dir_name}')\n",
    "              \n",
    "        save_model = True\n",
    "        if save_model:\n",
    "            Path(f'models/{dir_name}').mkdir(exist_ok=True)\n",
    "            model_name = f'run{run}_' + target[0].upper()\n",
    "            dump(clf, f'models/{dir_name}/{model_name}.joblib')\n",
    "        \n",
    "        exp_folder = EXPERIMENTS / dir_name / model_name\n",
    "\n",
    "        exp_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        feat_imp = pd.DataFrame(clf.feature_importances_, index=X_test.columns)\n",
    "        train_loss = pd.DataFrame(clf.train_score_)\n",
    "        feat_imp.sort_index().to_csv(exp_folder /  'feature_importance.csv')\n",
    "        train_loss.to_csv(exp_folder / 'training_loss.csv')\n",
    "        \n",
    "        pred_results = pd.DataFrame([y_test['Word'].values, y_true, y_pred], \n",
    "                                    index=['Word', 'T', 'P']).T\n",
    "        pred_results.to_csv(exp_folder / 'predictions.csv')\n",
    "              \n",
    "        results = precision_recall_fscore_support(y_true, y_pred, sample_weight=test_weights[target])\n",
    "        results = pd.DataFrame.from_dict(results)\n",
    "        results.index = metrics[1:]\n",
    "        results.to_csv(exp_folder / 'results.csv')\n",
    "        \n",
    "        with (exp_folder / 'accuracy.txt').open('a') as f:\n",
    "            f.write(f'{accuracy_score(y_true, y_pred, sample_weight=test_weights[target])}')\n",
    "            f.write('\\n')\n",
    "            f.write(f'{features}')\n",
    "            f.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "important aspects still to be implemented:\n",
    "- parameter tuning w/ grid search (train short models on subsets? try param_grid and GridSearch)\n",
    "- KCV (in combination with above)\n",
    "- some testing with different preprocessing and feature sets.\n",
    "- try importing seaborn and doing some EDA on feature importance data?\n",
    "- test Random Forest version?\n",
    "- additional feature extraction and tagging (dep relationships and sentence level features)\n",
    "- If trees are interesting as a final model, XGBoost > sklearn on most problems."
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
